{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc01e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f271c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dd4ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the objective function\n",
    "\n",
    "def f(x, A):\n",
    "    return 0.5 * x.T @ A @ x - np.sum(np.log(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128fe43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the gradient of the objective function\n",
    "\n",
    "def gradient_f(x, A):\n",
    "    return A @ x - 1/x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22b9a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Hessian of the objective function\n",
    "\n",
    "def hessian_f(x, A):\n",
    "    n = len(x)\n",
    "    H = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        H[i, i] = 1 / x[i]**2\n",
    "    return A + H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a972dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Newton's method for optimization\n",
    "\n",
    "def newtons_method(x_init, A, tol = 1e-10, max_iter = 100):\n",
    "    \n",
    "    x = x_init\n",
    "    alpha = 0.2\n",
    "    beta = 0.5\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        grad = gradient_f(x, A)\n",
    "        hess = hessian_f(x, A)\n",
    "        newtons_step = -np.linalg.solve(hess, grad) #calculate newton step\n",
    "        newtons_step_norm = np.linalg.norm(newtons_step)\n",
    "        stop_criterion = (newtons_step_norm ** 2)/2 #calculate stop criterion, a.k.a lambda squared divided by two\n",
    "        if stop_criterion <= tol: #exit newtons method if the stop criterion is smaller than our tolerance level \n",
    "            break\n",
    "        \n",
    "        #if we the norm of the newton step isn't sufficiently small we iterate with step length t\n",
    "        #making sure no component exit the dominion of x by adjusting step length t\n",
    "        t = 1.0 #initial step length\n",
    "        while True:\n",
    "            x_new = x + t * newtons_step #calculate new x\n",
    "            if np.all(x_new > 0): #if all components are larger than zero we perform backtracking line search with alpha and beta\n",
    "                while f(x_new, A) > f(x, A) + alpha*t*grad.T @ newtons_step: #perform back tracking line search for as long as the new x does not give us a better function value\n",
    "                    t *= beta \n",
    "                    x_new = x + t*newtons_step \n",
    "                x = x_new \n",
    "                break #the outer while loop is broken as we have found an x that is in the dominion and minimizes the objective function\n",
    "            else: #if the new x has components that are not larger than zero we decrease t\n",
    "                t /= 2\n",
    "              \n",
    "    return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dab1693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the conditions for your problem\n",
    "\n",
    "#size of problem\n",
    "n = 40 \n",
    "\n",
    "#initial point\n",
    "x0 = np.ones((n, 1))\n",
    "\n",
    "#generate a symmetric positive definite matrix A\n",
    "B = np.random.rand(n, n)\n",
    "A = B.T @ B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a1430d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vector x that minimizes the objective function is \n",
      " [[0.05114384]\n",
      " [0.05354114]\n",
      " [0.04965919]\n",
      " [0.05173349]\n",
      " [0.05488898]\n",
      " [0.04966593]\n",
      " [0.04675711]\n",
      " [0.05375179]\n",
      " [0.05609219]\n",
      " [0.05586438]\n",
      " [0.04919449]\n",
      " [0.0553016 ]\n",
      " [0.04634617]\n",
      " [0.05214484]\n",
      " [0.04597763]\n",
      " [0.04350675]\n",
      " [0.04553919]\n",
      " [0.05341649]\n",
      " [0.04758421]\n",
      " [0.04670531]\n",
      " [0.06234155]\n",
      " [0.05670205]\n",
      " [0.04729854]\n",
      " [0.04918513]\n",
      " [0.05317203]\n",
      " [0.05141376]\n",
      " [0.04569667]\n",
      " [0.04498605]\n",
      " [0.05068889]\n",
      " [0.04586424]\n",
      " [0.04871671]\n",
      " [0.04858153]\n",
      " [0.06045792]\n",
      " [0.05839956]\n",
      " [0.05487948]\n",
      " [0.04641029]\n",
      " [0.05157285]\n",
      " [0.0514875 ]\n",
      " [0.0516963 ]\n",
      " [0.05030472]]\n",
      "The function value of that vector x is equal to \n",
      " [[139.20621753]]\n"
     ]
    }
   ],
   "source": [
    "#Solve the problem using Newton's method\n",
    "\n",
    "x_optimal = newtons_method(x0, A)\n",
    "\n",
    "print(\"The vector x that minimizes the objective function is \\n\", x_optimal)\n",
    "print(\"The function value of that vector x is equal to \\n\", f(x_optimal, A))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e4474c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
